import requests
from datetime import datetime
from urllib.parse import urlparse
from django.utils import timezone
from django.core.files.base import ContentFile
from django.conf import settings
from .models import ExternalArticle, Source

NEWS_API_URL = "https://newsapi.org/v2/top-headlines"
API_KEY = getattr(settings, "NEWS_API_KEY", None)

def fetch_external_news(country='us', page_size=20, category=None, q=None):
    if not API_KEY:
        print("âŒ NEWS_API_KEY not set in settings or environment.")
        return 0

    params = {
        "apiKey": API_KEY,
        "pageSize": page_size,
        "country": country,
    }
    if category:
        params["category"] = category
    if q:
        params["q"] = q

    try:
        resp = requests.get(NEWS_API_URL, params=params, timeout=10)
        resp.raise_for_status()
        data = resp.json()
    except Exception as e:
        print("âŒ News API request failed:", e)
        return 0

    saved = 0

    for item in data.get("articles", []):
        url = item.get("url")
        if not url:
            continue

        # â›” Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø§ÛŒÙ† Ù…Ù‚Ø§Ù„Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ù†Ù‡
        if ExternalArticle.objects.filter(url=url).exists():
            print(f"âš ï¸ Ø®Ø¨Ø± ØªÚ©Ø±Ø§Ø±ÛŒ (skip): {url}")
            continue

        title = item.get("title") or "No title"
        description = item.get("description") or item.get("content") or ""
        image_url = item.get("urlToImage")
        source_info = item.get("source", {})
        published_at_raw = item.get("publishedAt")

        # ğŸ•’ ØªØ§Ø±ÛŒØ® Ø§Ù†ØªØ´Ø§Ø±
        published_at = None
        if published_at_raw:
            try:
                dt = datetime.fromisoformat(published_at_raw.replace("Z", "+00:00"))
                published_at = timezone.make_aware(dt)
            except Exception:
                published_at = None

        # ğŸ“° Ù…Ù†Ø¨Ø¹ Ø®Ø¨Ø±
        source_obj = None
        src_name = source_info.get("name")
        src_url = source_info.get("url")
        if src_name:
            source_obj, _ = Source.objects.get_or_create(name=src_name, defaults={"url": src_url})

        # ğŸ“¦ Ø§ÛŒØ¬Ø§Ø¯ Ø¢Ø¨Ø¬Ú©Øª Ù…Ù‚Ø§Ù„Ù‡
        article = ExternalArticle(
            source=source_obj,
            title=title,
            description=description,
            url=url,
            published_at=published_at,
        )

        # ğŸ–¼ Ø°Ø®ÛŒØ±Ù‡ Ø¹Ú©Ø³
        if image_url:
            try:
                headers = {"User-Agent": "Mozilla/5.0"}
                img_resp = requests.get(image_url, timeout=10, headers=headers)
                if img_resp.status_code == 200 and img_resp.content:
                    parsed = urlparse(image_url)
                    file_name = parsed.path.split("/")[-1] or "image.jpg"
                    if not file_name.lower().endswith((".jpg", ".jpeg", ".png", ".webp")):
                        file_name += ".jpg"
                    article.image.save(file_name, ContentFile(img_resp.content), save=False)
            except Exception as e:
                print("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¹Ú©Ø³:", e)

        # ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        try:
            article.save()
            saved += 1
            print(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {title[:50]}...")
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ({url}): {e}")

    print(f"âœ… Saved {saved} new external articles.")
    return saved
