import requests
from bs4 import BeautifulSoup
from datetime import datetime
from .models import NewsArticle
import re

def fetch_news_from_isna(limit=20):
    RSS_URL = "https://www.isna.ir/rss"
    try:
        response = requests.get(RSS_URL, timeout=10)
        response.raise_for_status()
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª RSS Ø§ÛŒØ³Ù†Ø§: {e}")
        return 0

    soup = BeautifulSoup(response.content, "xml")
    items = soup.find_all("item")[:limit]
    added_count = 0

    for item in items:
        title = item.title.text if item.title else "Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†"
        description = item.description.text if item.description else ""
        url = item.link.text if item.link else None
        pub_date = item.pubDate.text if item.pubDate else None
        
        # Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµÙˆÛŒØ±
        image_url = None
        
        # Ø±ÙˆØ´ Û±: Ø§Ø² ØªÚ¯ enclosure
        enclosure = item.find("enclosure")
        if enclosure and enclosure.get('url'):
            image_url = enclosure.get('url')
            print(f"ğŸ“¸ Ø±ÙˆØ´ Û± - enclosure: {image_url}")
        
        # Ø±ÙˆØ´ Û²: Ø§Ø² ØªÚ¯ media:content
        if not image_url:
            media_content = item.find("media:content")
            if media_content and media_content.get('url'):
                image_url = media_content.get('url')
                print(f"ğŸ“¸ Ø±ÙˆØ´ Û² - media:content: {image_url}")
        
        # Ø±ÙˆØ´ Û³: Ø§Ø² description Ø¨Ø§ regex
        if not image_url and description:
            # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ù„ÛŒÙ†Ú© ØªØµÙˆÛŒØ± Ø¯Ø± description
            img_patterns = [
                r'src="([^"]+\.(jpg|jpeg|png|gif))"',
                r'src="(https://[^"]+)"',
                r'<img[^>]+src="([^"]+)"'
            ]
            
            for pattern in img_patterns:
                match = re.search(pattern, description, re.IGNORECASE)
                if match:
                    image_url = match.group(1)
                    print(f"ğŸ“¸ Ø±ÙˆØ´ Û³ - Ø§Ø² description: {image_url}")
                    break
        
        # Ø±ÙˆØ´ Û´: Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² ØªØµÙˆÛŒØ±ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø§Ø² Ù…Ø­ØªÙˆØ§ÛŒ CDATA Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒÙ…
        if not image_url:
            # Ø¨Ø¹Ø¶ÛŒ RSS Ù‡Ø§ ØªØµÙˆÛŒØ± Ø±Ùˆ Ø¯Ø± CDATA Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù†
            cdata_match = re.search(r'<img[^>]*src="([^"]+)"[^>]*>', str(item), re.IGNORECASE)
            if cdata_match:
                image_url = cdata_match.group(1)
                print(f"ğŸ“¸ Ø±ÙˆØ´ Û´ - Ø§Ø² CDATA: {image_url}")

        # Ù„Ø§Ú¯ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯
        print(f"âœ… Ø¹Ù†ÙˆØ§Ù†: {title[:50]}...")
        print(f"ğŸ“¸ ØªØµÙˆÛŒØ± ÛŒØ§ÙØª Ø´Ø¯Ù‡: {image_url}")
        print("---")

        if not url or NewsArticle.objects.filter(url=url).exists():
            continue

        published_at = None
        try:
            published_at = datetime.strptime(pub_date, "%a, %d %b %Y %H:%M:%S %z")
        except Exception:
            try:
                published_at = datetime.strptime(pub_date, "%a, %d %b %Y %H:%M:%S %Z")
            except Exception:
                pass

        NewsArticle.objects.create(
            title=title,
            description=description,
            url=url,
            image_url=image_url,
            published_at=published_at,
        )
        added_count += 1

    print(f"âœ… {added_count} Ø®Ø¨Ø± Ø§Ø² Ø§ÛŒØ³Ù†Ø§ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")
    return added_count